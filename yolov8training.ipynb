{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ca238b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Loaded 800 training images from 'tb' category.\n",
      "\n",
      "üñºÔ∏è Preview: tb0003.png (PNG, (512, 512))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# --- Define the base directory where 'tb' category images are stored ---\n",
    "image_dir = r\"C:\\Users\\muham\\Downloads\\archive (1)\\tbx11k-simplified\\yolo_training\\data\\tb\"\n",
    "valid_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
    "\n",
    "image_data = []\n",
    "\n",
    "if not os.path.isdir(image_dir):\n",
    "    print(f\"‚ùå Error: Image directory not found at {image_dir}\")\n",
    "else:\n",
    "    for file in os.listdir(image_dir):\n",
    "        ext = os.path.splitext(file)[1].lower()\n",
    "        if ext in valid_exts:\n",
    "            full_path = os.path.join(image_dir, file)\n",
    "            image_data.append({\n",
    "                \"filename\": file,\n",
    "                \"path\": full_path\n",
    "            })\n",
    "\n",
    "    print(f\"\\n‚úÖ Loaded {len(image_data)} training images from 'tb' category.\")\n",
    "\n",
    "    # --- Optional: Show first image as verification ---\n",
    "    if image_data:\n",
    "        try:\n",
    "            img = Image.open(image_data[0]['path'])\n",
    "            print(f\"\\nüñºÔ∏è Preview: {image_data[0]['filename']} ({img.format}, {img.size})\")\n",
    "            img.show()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Could not load image: {e}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No images were found with valid extensions.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fed3a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Created YOLO directory structure in: D:\\yolo_training_tb_only\n",
      "üìÑ Loaded 8811 rows from D:\\yolo_training\\data.csv\n",
      "üëç Filtered to 1211 rows with bounding boxes.\n",
      "üìä Processed 1211 bounding boxes into YOLO format.\n",
      "üìä Split: 639 train images, 160 validation images.\n",
      "üìä Resulting in: 973 train annotations, 238 validation annotations.\n",
      "\n",
      "‚öôÔ∏è Processing train split...\n",
      "‚úÖ Processed 639 images and their labels for train split.\n",
      "\n",
      "‚öôÔ∏è Processing validation split...\n",
      "‚úÖ Processed 160 images and their labels for validation split.\n",
      "\n",
      "üìÑ data.yaml created at: D:\\yolo_training_tb_only\\data.yaml\n",
      "\n",
      "üéâ Dataset preparation complete!\n",
      "‚û°Ô∏è  Root path: D:\\yolo_training_tb_only\n",
      "    images/train: 639 files\n",
      "    images/val:   160 files\n",
      "    labels/train: 639 files\n",
      "    labels/val:   160 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from shutil import copyfile, rmtree # Added rmtree for cleanup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast # For safely evaluating string-represented dictionaries\n",
    "\n",
    "# === 1. Configuration ===\n",
    "# Base directory where the YOLO dataset structure will be created\n",
    "base_dir = r\"D:\\yolo_training_tb_only\" # Changed to a new clean directory\n",
    "# Path to your original CSV file\n",
    "csv_path = r\"D:\\yolo_training\\data.csv\" # Assuming this is where your original data.csv is\n",
    "# Directory where your source images are located\n",
    "image_source_dir = r\"D:\\yolo_training\\data\\tb\" # Source of all .png images\n",
    "\n",
    "# Define output directories\n",
    "images_out_dir = os.path.join(base_dir, \"images\")\n",
    "labels_out_dir = os.path.join(base_dir, \"labels\")\n",
    "train_images_dir = os.path.join(images_out_dir, \"train\")\n",
    "val_images_dir = os.path.join(images_out_dir, \"val\")\n",
    "train_labels_dir = os.path.join(labels_out_dir, \"train\")\n",
    "val_labels_dir = os.path.join(labels_out_dir, \"val\")\n",
    "\n",
    "# YOLO class configuration\n",
    "class_name = \"tb\"\n",
    "class_id = 0 # Since we only have one class 'tb'\n",
    "\n",
    "# Train/Validation split ratio\n",
    "VAL_SPLIT_RATIO = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# === 2. Cleanup and Directory Creation ===\n",
    "# Clean up old directories if they exist to ensure a fresh start\n",
    "if os.path.exists(base_dir):\n",
    "    print(f\"üßπ Cleaning up old directory: {base_dir}\")\n",
    "    rmtree(base_dir)\n",
    "\n",
    "# Create the required YOLO directory structure\n",
    "os.makedirs(train_images_dir, exist_ok=True)\n",
    "os.makedirs(val_images_dir, exist_ok=True)\n",
    "os.makedirs(train_labels_dir, exist_ok=True)\n",
    "os.makedirs(val_labels_dir, exist_ok=True)\n",
    "print(f\"üìÅ Created YOLO directory structure in: {base_dir}\")\n",
    "\n",
    "# === 3. Load and Filter Data ===\n",
    "df_all = pd.read_csv(csv_path)\n",
    "print(f\"üìÑ Loaded {len(df_all)} rows from {csv_path}\")\n",
    "\n",
    "# Filter out rows where 'bbox' is 'none'\n",
    "df_bbox = df_all[df_all['bbox'] != 'none'].copy()\n",
    "print(f\"üëç Filtered to {len(df_bbox)} rows with bounding boxes.\")\n",
    "\n",
    "if df_bbox.empty:\n",
    "    print(\"‚ùå No rows with bounding boxes found. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# === 4. Bounding Box Conversion and Class Assignment ===\n",
    "# Helper function to convert bbox string/dict to YOLO format\n",
    "def bbox_to_yolo_format(bbox_item, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Converts a bounding box from {'xmin', 'ymin', 'width', 'height'}\n",
    "    or {'xmin', 'ymin', 'xmax', 'ymax'} format to YOLO format.\n",
    "    (x_center_norm, y_center_norm, width_norm, height_norm)\n",
    "    \"\"\"\n",
    "    if isinstance(bbox_item, str):\n",
    "        try:\n",
    "            bbox = ast.literal_eval(bbox_item)\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            print(f\"Error parsing bbox string: {bbox_item}. Error: {e}\")\n",
    "            return None\n",
    "    elif isinstance(bbox_item, dict):\n",
    "        bbox = bbox_item\n",
    "    else:\n",
    "        print(f\"Invalid bbox_item type: {type(bbox_item)}\")\n",
    "        return None\n",
    "\n",
    "    img_w = float(img_width)\n",
    "    img_h = float(img_height)\n",
    "\n",
    "    # Check if bbox is in (xmin, ymin, width, height) format\n",
    "    if 'width' in bbox and 'height' in bbox:\n",
    "        xmin = float(bbox['xmin'])\n",
    "        ymin = float(bbox['ymin'])\n",
    "        bbox_w = float(bbox['width'])\n",
    "        bbox_h = float(bbox['height'])\n",
    "        \n",
    "        x_center = (xmin + bbox_w / 2) / img_w\n",
    "        y_center = (ymin + bbox_h / 2) / img_h\n",
    "        norm_w = bbox_w / img_w\n",
    "        norm_h = bbox_h / img_h\n",
    "    # Check if bbox is in (xmin, ymin, xmax, ymax) format\n",
    "    elif 'xmax' in bbox and 'ymax' in bbox:\n",
    "        xmin = float(bbox['xmin'])\n",
    "        ymin = float(bbox['ymin'])\n",
    "        xmax = float(bbox['xmax'])\n",
    "        ymax = float(bbox['ymax'])\n",
    "\n",
    "        x_center = ((xmin + xmax) / 2) / img_w\n",
    "        y_center = ((ymin + ymax) / 2) / img_h\n",
    "        norm_w = (xmax - xmin) / img_w\n",
    "        norm_h = (ymax - ymin) / img_h\n",
    "    else:\n",
    "        print(f\"Unsupported bbox format: {bbox}\")\n",
    "        return None\n",
    "        \n",
    "    return x_center, y_center, norm_w, norm_h\n",
    "\n",
    "# Apply the conversion\n",
    "yolo_coords = []\n",
    "for index, row in df_bbox.iterrows():\n",
    "    coords = bbox_to_yolo_format(row['bbox'], row['image_width'], row['image_height'])\n",
    "    if coords:\n",
    "        yolo_coords.append(coords)\n",
    "    else:\n",
    "        # Append NaNs if conversion failed, to maintain DataFrame structure\n",
    "        yolo_coords.append((np.nan, np.nan, np.nan, np.nan))\n",
    "\n",
    "\n",
    "df_bbox[['x_center', 'y_center', 'width_norm', 'height_norm']] = pd.DataFrame(yolo_coords, index=df_bbox.index)\n",
    "\n",
    "# Drop rows where conversion might have failed (if any)\n",
    "df_bbox.dropna(subset=['x_center'], inplace=True)\n",
    "\n",
    "# Assign class_id (all are 'tb' so class_id is 0)\n",
    "df_bbox['class_id'] = class_id\n",
    "print(f\"üìä Processed {len(df_bbox)} bounding boxes into YOLO format.\")\n",
    "\n",
    "# === 5. Split Data by Image Filename ===\n",
    "# Get unique filenames to ensure images are not split across train/val\n",
    "unique_filenames = df_bbox['fname'].unique()\n",
    "train_fnames, val_fnames = train_test_split(\n",
    "    unique_filenames,\n",
    "    test_size=VAL_SPLIT_RATIO,\n",
    "    random_state=RANDOM_STATE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_df = df_bbox[df_bbox['fname'].isin(train_fnames)].copy()\n",
    "val_df = df_bbox[df_bbox['fname'].isin(val_fnames)].copy()\n",
    "\n",
    "print(f\"üìä Split: {len(train_fnames)} train images, {len(val_fnames)} validation images.\")\n",
    "print(f\"üìä Resulting in: {len(train_df)} train annotations, {len(val_df)} validation annotations.\")\n",
    "\n",
    "\n",
    "# === 6. Process and Save Data for Each Split ===\n",
    "def process_and_save_split(df_split, image_dest_dir, label_dest_dir, split_name):\n",
    "    print(f\"\\n‚öôÔ∏è Processing {split_name} split...\")\n",
    "    copied_images = set() # To copy each image only once\n",
    "\n",
    "    for fname, group in df_split.groupby('fname'):\n",
    "        # --- Copy Image (once per unique filename) ---\n",
    "        if fname not in copied_images:\n",
    "            src_img_path = os.path.join(image_source_dir, fname)\n",
    "            dst_img_path = os.path.join(image_dest_dir, fname)\n",
    "            if os.path.exists(src_img_path):\n",
    "                copyfile(src_img_path, dst_img_path)\n",
    "                copied_images.add(fname)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Image missing: {src_img_path}. Skipping this image.\")\n",
    "                continue # Skip label creation if image is missing\n",
    "\n",
    "        # --- Create Label File (one file per image, multiple lines for multiple bboxes) ---\n",
    "        label_filename = os.path.splitext(fname)[0] + \".txt\"\n",
    "        label_path = os.path.join(label_dest_dir, label_filename)\n",
    "\n",
    "        with open(label_path, 'w') as f: # Use 'w' to overwrite if file exists from a previous run\n",
    "            for _, row in group.iterrows():\n",
    "                # Format: class_id x_center y_center width height\n",
    "                yolo_line = f\"{int(row['class_id'])} {row['x_center']:.6f} {row['y_center']:.6f} {row['width_norm']:.6f} {row['height_norm']:.6f}\\n\"\n",
    "                f.write(yolo_line)\n",
    "    print(f\"‚úÖ Processed {len(copied_images)} images and their labels for {split_name} split.\")\n",
    "\n",
    "process_and_save_split(train_df, train_images_dir, train_labels_dir, \"train\")\n",
    "process_and_save_split(val_df, val_images_dir, val_labels_dir, \"validation\")\n",
    "\n",
    "# === 7. Create data.yaml file ===\n",
    "# Paths for data.yaml should be relative to the base_dir if yaml is also in base_dir\n",
    "# Or absolute if YOLO will be run from a different location.\n",
    "# For simplicity, using paths relative to where the YAML file will be.\n",
    "yaml_content = f\"\"\"\n",
    "train: ./images/train\n",
    "val: ./images/val\n",
    "\n",
    "nc: 1  # number of classes\n",
    "names: ['{class_name}'] # class names\n",
    "\"\"\"\n",
    "\n",
    "yaml_path = os.path.join(base_dir, \"data.yaml\")\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(f\"\\nüìÑ data.yaml created at: {yaml_path}\")\n",
    "print(\"\\nüéâ Dataset preparation complete!\")\n",
    "print(f\"‚û°Ô∏è  Root path: {base_dir}\")\n",
    "print(f\"    images/train: {len(os.listdir(train_images_dir))} files\")\n",
    "print(f\"    images/val:   {len(os.listdir(val_images_dir))} files\")\n",
    "print(f\"    labels/train: {len(os.listdir(train_labels_dir))} files\")\n",
    "print(f\"    labels/val:   {len(os.listdir(val_labels_dir))} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dbedece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing YOLO model: yolov8m.pt\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49.7M/49.7M [01:37<00:00, 533kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting YOLOv8m training...\n",
      "Ultralytics 8.3.149  Python-3.13.3 torch-2.7.1+cu128 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\yolo_training_tb_only\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=run1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\yolo_training_tb_only\\yolov8m_tb_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\yolo_training_tb_only\\yolov8m_tb_training\\run1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 469.145.9 MB/s, size: 354.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\yolo_training_tb_only\\labels\\train.cache... 639 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 639/639 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 5.72.6 MB/s, size: 368.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\yolo_training_tb_only\\labels\\val.cache... 160 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to D:\\yolo_training_tb_only\\yolov8m_tb_training\\run1\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mD:\\yolo_training_tb_only\\yolov8m_tb_training\\run1\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      3.49G      2.106      2.766      2.176         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:36<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:11<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238    0.00172      0.324    0.00125    0.00032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      3.49G      2.135      2.484      2.181         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:37<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:14<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238     0.0679      0.139     0.0226    0.00549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      3.47G      2.088      2.312      2.167         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:37<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:13<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238     0.0348     0.0252    0.00944    0.00363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      3.46G      2.145      2.341      2.174         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:37<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:17<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.317      0.387      0.278     0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      3.44G      2.143      2.342      2.192         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:45<00:00,  1.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:17<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.104      0.214     0.0701     0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      3.46G      2.058      2.231      2.115         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [02:23<00:00,  1.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:13<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.259      0.176      0.132      0.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      3.46G       1.97      2.146      2.054         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:24<00:00,  1.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:14<00:00,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.447      0.471      0.434       0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      3.46G      1.989      2.149      2.053         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:50<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:18<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.436      0.529      0.443       0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      3.45G      1.898      2.061      1.994         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:29<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:11<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.451      0.445       0.38      0.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      3.45G      1.861      2.006      1.975         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:59<00:00,  1.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:11<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.474      0.408      0.398      0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      3.45G      1.902      2.017      1.962         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:46<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:06<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.414      0.508      0.391      0.141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      3.43G      1.886       1.93       1.96         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:42<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.547      0.529      0.527      0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      3.44G      1.919      1.943      2.004         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:34<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:12<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.441      0.471      0.398      0.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      3.44G       1.89      1.945      1.994         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:47<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.648        0.5      0.579      0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      3.44G      1.875      1.938      1.966         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:40<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:05<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238       0.37      0.286      0.287     0.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      3.43G      1.801      1.942      1.934         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:48<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:13<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.531        0.5      0.515      0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      3.42G      1.864      1.866      1.967         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:34<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:06<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.554      0.501      0.538      0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      3.45G        1.8      1.857      1.907         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:34<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:16<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.521      0.475      0.461      0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      3.45G      1.793      1.806      1.923         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:56<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:20<00:00,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.634      0.563       0.56      0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      3.45G      1.781      1.738      1.879         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:46<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:25<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.693      0.542      0.585      0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      3.43G      1.829      1.815      1.952         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:44<00:00,  1.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:37<00:00,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.764      0.612      0.648      0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      3.43G       1.77      1.804      1.894         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:19<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:13<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.621      0.521      0.533      0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      3.44G      1.732      1.753      1.851         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:01<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:13<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.722      0.466      0.561      0.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      3.45G      1.775       1.75      1.859         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:31<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:16<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.714      0.557      0.627      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      3.44G      1.747      1.809      1.942         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:47<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:15<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.705      0.584      0.639      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      3.44G      1.746      1.736      1.861         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:10<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:12<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.753      0.584      0.644      0.286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      3.45G      1.771       1.75      1.887         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:39<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:13<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238        0.6      0.547       0.57      0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      3.42G      1.729      1.705      1.873         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:31<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:23<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.793      0.538      0.677      0.284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      3.45G      1.706      1.656      1.838         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:58<00:00,  1.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:17<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.634      0.618      0.611      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      3.45G      1.734      1.698      1.842         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:10<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:06<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238        0.7       0.55      0.619       0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      3.42G      1.719      1.669      1.851         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:03<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:08<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.689      0.592      0.646      0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      3.42G      1.693      1.635      1.806         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:34<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:06<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.777      0.601      0.695      0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      3.45G       1.69      1.628      1.827         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:34<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:23<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.704       0.59      0.637      0.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      3.42G      1.668      1.585      1.792         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:17<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:26<00:00,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.709      0.622       0.68      0.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      3.42G      1.683      1.585      1.796         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [01:09<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:25<00:00,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        238      0.736      0.639       0.72      0.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      3.44G      1.691      1.591      1.823         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:42<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:09<00:06,  1.53s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m start_time = time.time()\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting YOLOv8m training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_yaml_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatience_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     45\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m end_time = time.time()\n\u001b[32m     48\u001b[39m training_duration = end_time - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\model.py:797\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    794\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    796\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m797\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:227\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    224\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:459\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.val \u001b[38;5;129;01mor\u001b[39;00m final_epoch \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stopper.possible_stop \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[38;5;28mself\u001b[39m.metrics, \u001b[38;5;28mself\u001b[39m.fitness = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[38;5;28mself\u001b[39m.save_metrics(metrics={**\u001b[38;5;28mself\u001b[39m.label_loss_items(\u001b[38;5;28mself\u001b[39m.tloss), **\u001b[38;5;28mself\u001b[39m.metrics, **\u001b[38;5;28mself\u001b[39m.lr})\n\u001b[32m    461\u001b[39m \u001b[38;5;28mself\u001b[39m.stop |= \u001b[38;5;28mself\u001b[39m.stopper(epoch + \u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.fitness) \u001b[38;5;129;01mor\u001b[39;00m final_epoch\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:656\u001b[39m, in \u001b[36mBaseTrainer.validate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    648\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    649\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    650\u001b[39m \u001b[33;03m    Run validation on test set using self.validator.\u001b[39;00m\n\u001b[32m    651\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    654\u001b[39m \u001b[33;03m        fitness (float): Fitness score for the validation.\u001b[39;00m\n\u001b[32m    655\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m     fitness = metrics.pop(\u001b[33m\"\u001b[39m\u001b[33mfitness\u001b[39m\u001b[33m\"\u001b[39m, -\u001b[38;5;28mself\u001b[39m.loss.detach().cpu().numpy())  \u001b[38;5;66;03m# use loss as fitness measure if not found\u001b[39;00m\n\u001b[32m    658\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.best_fitness \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.best_fitness < fitness:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\validator.py:213\u001b[39m, in \u001b[36mBaseValidator.__call__\u001b[39m\u001b[34m(self, trainer, model)\u001b[39m\n\u001b[32m    210\u001b[39m     batch = \u001b[38;5;28mself\u001b[39m.preprocess(batch)\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m=\u001b[49m\u001b[43maugment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[38;5;66;03m# Loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\utils\\ops.py:61\u001b[39m, in \u001b[36mProfile.__exit__\u001b[39m\u001b[34m(self, type, value, traceback)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Stop timing.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[38;5;28mself\u001b[39m.dt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m - \u001b[38;5;28mself\u001b[39m.start  \u001b[38;5;66;03m# delta-time\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28mself\u001b[39m.t += \u001b[38;5;28mself\u001b[39m.dt\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\utils\\ops.py:71\u001b[39m, in \u001b[36mProfile.time\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get current time with CUDA synchronization if applicable.\"\"\"\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cuda:\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m time.perf_counter()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\cuda\\__init__.py:1040\u001b[39m, in \u001b[36msynchronize\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m   1038\u001b[39m _lazy_init()\n\u001b[32m   1039\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.cuda.device(device):\n\u001b[32m-> \u001b[39m\u001b[32m1040\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# === 1. Configuration ===\n",
    "base_dir = r\"D:\\yolo_training_tb_only\"\n",
    "data_yaml_path = os.path.join(base_dir, \"data.yaml\")\n",
    "model_name = 'yolov8m.pt'  # Using official YOLOv8 medium model\n",
    "epochs = 100\n",
    "image_size = 640\n",
    "patience_epochs = 20\n",
    "project_name = \"yolov8m_tb_training\"\n",
    "experiment_name = \"run1\"\n",
    "batch_size = 8\n",
    "workers = 4\n",
    "device_to_use = 0  # Set to 0 for GPU, 'cpu' for CPU\n",
    "\n",
    "# === 2. Sanity Checks ===\n",
    "if not os.path.exists(data_yaml_path):\n",
    "    raise FileNotFoundError(f\"data.yaml not found at {data_yaml_path}\")\n",
    "\n",
    "# === 3. Initialize and Train YOLOv8m Model ===\n",
    "print(f\"Initializing YOLO model: {model_name}\")\n",
    "model = YOLO(model_name)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Starting YOLOv8m training...\")\n",
    "results = model.train(\n",
    "    data=data_yaml_path,\n",
    "    epochs=epochs,\n",
    "    imgsz=image_size,\n",
    "    batch=batch_size,\n",
    "    patience=patience_epochs,\n",
    "    project=os.path.join(base_dir, project_name),\n",
    "    name=experiment_name,\n",
    "    device=device_to_use,\n",
    "    workers=workers,\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "training_duration = end_time - start_time\n",
    "print(f\"Training completed in {training_duration:.2f} seconds.\")\n",
    "\n",
    "# === 4. Locate and Copy Best Weights ===\n",
    "run_dir = results.save_dir\n",
    "weights_dir = os.path.join(run_dir, 'weights')\n",
    "best_weights_path = os.path.join(weights_dir, 'best.pt')\n",
    "last_weights_path = os.path.join(weights_dir, 'last.pt')\n",
    "\n",
    "final_best_weight_name = f\"best_{os.path.splitext(model_name)[0]}_tb_e{epochs}_b{batch_size}.pt\"\n",
    "destination_best_weights_path = os.path.join(base_dir, final_best_weight_name)\n",
    "\n",
    "if os.path.exists(best_weights_path):\n",
    "    shutil.copy2(best_weights_path, destination_best_weights_path)\n",
    "    print(f\"Best weights copied to: {destination_best_weights_path}\")\n",
    "else:\n",
    "    print(\"best.pt not found. Checking for last.pt.\")\n",
    "    if os.path.exists(last_weights_path):\n",
    "        destination_last_weights_path = os.path.join(base_dir, f\"last_{os.path.splitext(model_name)[0]}_tb_e{epochs}_b{batch_size}.pt\")\n",
    "        shutil.copy2(last_weights_path, destination_last_weights_path)\n",
    "        print(f\"Last weights copied to: {destination_last_weights_path}\")\n",
    "    else:\n",
    "        print(f\"Neither best.pt nor last.pt found in {weights_dir}.\")\n",
    "\n",
    "# === 5. Performance Metrics ===\n",
    "results_csv_path = os.path.join(run_dir, 'results.csv')\n",
    "json_summary_path = os.path.join(run_dir, 'training_summary.json')\n",
    "\n",
    "if os.path.exists(results_csv_path):\n",
    "    df_results = pd.read_csv(results_csv_path)\n",
    "    df_results.columns = df_results.columns.str.strip().str.replace('/', '_', regex=False).str.replace('(', '_', regex=False).str.replace(')', '', regex=False)\n",
    "\n",
    "    last_epoch_metrics = df_results.iloc[-1].to_dict()\n",
    "    last_epoch_metrics['training_duration_sec'] = training_duration\n",
    "\n",
    "    with open(json_summary_path, 'w') as f:\n",
    "        json.dump(last_epoch_metrics, f, indent=4)\n",
    "    print(f\"Training metrics saved to: {json_summary_path}\")\n",
    "\n",
    "    # === Plotting ===\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Box Loss\n",
    "    plt.subplot(2, 2, 1)\n",
    "    if 'train_box_loss' in df_results.columns and 'val_box_loss' in df_results.columns:\n",
    "        plt.plot(df_results['epoch'], df_results['train_box_loss'], label='Train Box Loss')\n",
    "        plt.plot(df_results['epoch'], df_results['val_box_loss'], label='Validation Box Loss')\n",
    "        plt.title('Box Loss vs. Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Box loss data not found', ha='center', va='center')\n",
    "\n",
    "    # mAP\n",
    "    plt.subplot(2, 2, 2)\n",
    "    if 'metrics_mAP50_B' in df_results.columns:\n",
    "        plt.plot(df_results['epoch'], df_results['metrics_mAP50_B'], label='mAP@0.50 (B)')\n",
    "    if 'metrics_mAP50-95_B' in df_results.columns:\n",
    "        plt.plot(df_results['epoch'], df_results['metrics_mAP50-95_B'], label='mAP@0.50-0.95 (B)')\n",
    "    if 'metrics_mAP50_B' in df_results.columns or 'metrics_mAP50-95_B' in df_results.columns:\n",
    "        plt.title('mAP vs. Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('mAP')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'mAP data not found', ha='center', va='center')\n",
    "\n",
    "    # Precision & Recall\n",
    "    plt.subplot(2, 2, 3)\n",
    "    if 'metrics_precision_B' in df_results.columns:\n",
    "        plt.plot(df_results['epoch'], df_results['metrics_precision_B'], label='Precision (B)')\n",
    "    if 'metrics_recall_B' in df_results.columns:\n",
    "        plt.plot(df_results['epoch'], df_results['metrics_recall_B'], label='Recall (B)')\n",
    "    if 'metrics_precision_B' in df_results.columns or 'metrics_recall_B' in df_results.columns:\n",
    "        plt.title('Precision & Recall vs. Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Precision/Recall data not found', ha='center', va='center')\n",
    "\n",
    "    # Class Loss\n",
    "    plt.subplot(2, 2, 4)\n",
    "    if 'train_cls_loss' in df_results.columns and 'val_cls_loss' in df_results.columns:\n",
    "        plt.plot(df_results['epoch'], df_results['train_cls_loss'], label='Train Class Loss')\n",
    "        plt.plot(df_results['epoch'], df_results['val_cls_loss'], label='Validation Class Loss')\n",
    "        plt.title('Class Loss vs. Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Class loss data not found', ha='center', va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plots_save_path = os.path.join(run_dir, 'performance_plots.png')\n",
    "    plt.savefig(plots_save_path)\n",
    "    print(f\"Performance plots saved to: {plots_save_path}\")\n",
    "    plt.close()\n",
    "else:\n",
    "    print(f\"results.csv not found at {results_csv_path}. Cannot display detailed metrics or plots.\")\n",
    "\n",
    "# === 6. GPU Memory Usage ===\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory_allocated = torch.cuda.memory_allocated(device_to_use) / (1024 ** 3)\n",
    "    gpu_memory_reserved = torch.cuda.memory_reserved(device_to_use) / (1024 ** 3)\n",
    "    print(f\"GPU Memory Allocated: {gpu_memory_allocated:.2f} GB\")\n",
    "    print(f\"GPU Memory Reserved: {gpu_memory_reserved:.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Skipping GPU memory usage logging.\")\n",
    "\n",
    "# === 7. Display Confusion Matrix ===\n",
    "confusion_matrix_path = os.path.join(run_dir, 'confusion_matrix.png')\n",
    "confusion_matrix_normalized_path = os.path.join(run_dir, 'confusion_matrix_normalized.png')\n",
    "\n",
    "if os.path.exists(confusion_matrix_path):\n",
    "    print(f\"Confusion Matrix saved at: {confusion_matrix_path}\")\n",
    "    if os.path.exists(confusion_matrix_normalized_path):\n",
    "        print(f\"Normalized Confusion Matrix saved at: {confusion_matrix_normalized_path}\")\n",
    "else:\n",
    "    print(\"Confusion matrix plot not found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
